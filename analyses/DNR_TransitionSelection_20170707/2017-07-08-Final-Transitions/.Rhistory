switch(parts, text(0, .5, labels, ...), text(rbind(c(0,.5),
c(1,.5)), labels, ...), text(rbind(c(0,.5),c(1,.5),c(.5,-1.3)),
labels, ...))
#other components and labels
xy<-par('usr')
if(nrow(x$total)==4){
text(xy[2]-0.7*diff(xy[1:2]), xy[3]+0.05*diff(xy[3:4]),
paste('Conditional =', round(x$conditional[2]*100,digits)), pos=2, ...)
}
text(xy[2]-0.05*diff(xy[1:2]), xy[3]+0.05*diff(xy[3:4]),
paste('Residual =', round(x$residual[2]*100,digits)), pos=2, ...)
#plot title
if(which=='total') title('Partition = Percent of Total Variance')
else if (which=='constrained') title('Partition = Percent of Explained Variance')
invisible()
}
`qqnorm.plots` <-
function(x,var='',by='',save.plot=FALSE,
na.rm=TRUE,col.point='blue',col.line='red',las=1,...){
old.par<-par(no.readonly=TRUE)
on.exit(par(old.par))
if(!var==''){
y<-subset(x,select=eval(parse(text=var))) #select variables to summarize
y<-as.data.frame(y)
}
else{y<-as.data.frame(x)}
if(by==''){ #QQnorm plots w/o groups
for(i in 1:ncol(y)){ #loop thru variables
qqnorm(y[,i],datax=TRUE,col=col.point,las=las,
main=paste('Normal Q-Q Plot of',names(y[i]),sep=' '),...)
y.IQR<-IQR(y[,i],na.rm=na.rm)
if(y.IQR>0){ #add qqline
qqline(y[,i],datax=TRUE,col=col.line,...)
} #end qqline
if(save.plot==TRUE){ #save plot
dev.print(jpeg,file=paste('qqnorm.',names(y[i]),'.jpg',sep=''),width=800,height=600)
} #end save plot
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
} #end qqnorm w/o groups
else{ #QQnorm plots w/ groups
n<-by.names(x,by) #create by variable
y<-cbind(n,y) #bind with selected variables
groups<-levels(y[,2]) #create vector of group names
s<-floor(length(groups)^.5) #create multi-figure dimension
s<-c(s,ceiling(length(groups)/s)) #create multi-figure dimensions
for(i in 3:ncol(y)){ #loop thru variables
par(mfrow=s,mar=c(5,5,4,2))	#graphics settings
for(j in 1:length(groups)){ #loop thru groups
z<-y[y[,2]==groups[j],] #select records for group j
qqnorm(z[,i],datax=TRUE,col=col.point,las=las,
main=groups[j],
ylab=paste('Sample quantiles of',names(z[i]),sep=' '),...)
z.IQR<-IQR(z[,i],na.rm=na.rm)
if(z.IQR>0){ #add qqline
qqline(z[,i],datax=TRUE,col=col.line,...)
} #end qqline
if(j==length(groups) & save.plot==TRUE){
dev.print(jpeg,file=paste('qqnorm.',names(z[i]),'.jpg',sep=''),width=800,height=600)
} #end save
} #end loop thru groups
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
} #end qqnorm w/ groups
} #end function
`ran.split` <-
function(x,grouping='',prop=.5){
if(!grouping==''){
y<-cbind(grouping,x)
}
else{
y<-x #groups assumed to be in first column
}
N<-nrow(y)
g<-runif(N)
g[g<prop]<-0
g[g>=prop]<-1
y<-cbind(g,y)
y<-split(y,g)
y1<-y[[1]]
y2<-y[[2]]
calibrate<<-y1[,-c(1,2)]
validate<<-y2[,-c(1,2)]
grp.cal<<-y1[,2]
grp.val<<-y2[,2]
z1<-c(nrow(y1),nrow(y2))
z2<-round(c(nrow(y1)/N,nrow(y2)/N),2)
z1<-cbind(z1,z2)
colnames(z1)<-c('Number of samples','Proportion')
rownames(z1)<-c('Calibration set','Validation set')
z2<-table(grp.cal)
z3<-table(grp.val)
z<-list(z1,z2,z3)
names(z)<-c('Random Subset Summary:','Calibration Table','Validation Table')
return(z)
}
`redun.plot` <-
function(x,var='',perm=1000,quantiles=c(.025,.975),...){
old.par<-par(no.readonly=TRUE)
if(!var==''){
y<-subset(x,select=eval(parse(text=var))) #select variables to plot
z.obs<-as.matrix(cor(y,use='complete.obs'))
diag(z.obs)<-NA
for(i in 1:ncol(y)){ #loop thru variables
y.obs<-sort(z.obs[,i])
y.ran<-matrix(0,perm,length(y.obs))
for(j in 1:perm){
t1<-apply(y,2,sample) #permute data matrix
t2<-as.matrix(cor(t1,use='complete.obs'))
diag(t2)<-NA
t3<-sort(t2[,i])
if(length(t3)==length(y.obs)) y.ran[j,]<-t3
}
y.ran.lower<-apply(y.ran,2,quantile,probs=quantiles[1])
y.ran.upper<-apply(y.ran,2,quantile,probs=quantiles[2])
par(new=FALSE)
plot(y.obs,type='l',lwd=2,col='blue',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='Rank order of pairwise correlations',
ylab='Correlation',
main=paste('Redundancy of ',names(y[i]),' vs. random data',sep=''),...)
par(new=TRUE)
plot(y.ran.lower,type='l',lwd=2,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
par(new=TRUE)
plot(y.ran.upper,type='l',lwd=2,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
abline(h=0,col='red',lty=3,lwd=1,...)
legend(x='bottomright',inset=c(.1,.1),legend=c('Actual','Random (95CI)'),
col=c('blue','green'),lty=c(1,1),lwd=c(2,1))
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
}
else{
z.obs<-sort(as.vector(as.dist(cor(x,use='complete.obs'))))
z.ran<-matrix(0,perm,length(z.obs))
for(i in 1:perm){
t1<-apply(x,2,sample) #permute data matrix
t2<-sort(as.vector(as.dist(cor(t1,use='complete.obs'))))
if(length(t2)==length(z.obs)) z.ran[i,]<-t2
}
z.ran.lower<-apply(z.ran,2,quantile,probs=quantiles[1])
z.ran.upper<-apply(z.ran,2,quantile,probs=quantiles[2])
plot(z.obs,type='l',lwd=2,col='blue',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='Rank order of pairwise correlations',
ylab='Correlation',
main='Redundancy of actual vs. random data',...)
par(new=TRUE)
plot(z.ran.lower,type='l',lwd=1,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
par(new=TRUE)
plot(z.ran.upper,type='l',lwd=1,col='green',
xaxs='i',yaxs='i',ylim=c(-1,1),
xlab='',ylab='',main='',...)
abline(h=0,col='red',lty=3,lwd=1,...)
legend(x='bottomright',inset=c(.1,.1),legend=c('Actual','Random (95CI)'),
col=c('blue','green'),lty=c(1,1),lwd=c(2,1))
}
par(old.par)
}
`replace.missing` <-
function(x,var='',method='median',outfile=''){
if(!var==''){
y1<-subset(x,select=-eval(parse(text=var))) #select all other variables
y2<-subset(x,select=eval(parse(text=var))) #select all specified variables
}
else{
y2<-x #original variables
}
if(method=='mean'){ #for method=mean
for(i in names(y2)){ #loop through selected variables
t<-round(mean(y2[[i]],na.rm=TRUE),3) #compute mean for each variable
y2[is.na(y2[[i]]),i]<-t #assign mean value to missing value
}
}
if(method=='median'){ #for method=median
for(i in names(y2)){ #loop through selected variables
t<-median(y2[[i]],na.rm=TRUE) #compute median for each variable
y2[is.na(y2[[i]]),i]<-t #assign median value to missing value
}
}
if(!var==''){
z<-cbind(y1,y2) #combine deselected and (modified) selected variables
}
else{z<-y2}
if(!outfile==''){ #save outfile
write.table(z,file=paste(outfile,'.csv',sep=''),quote=FALSE,sep=',')
} #end save outfile
return(z)
} #end function
`scatter.plots` <-
function(data,y,x,lowess=TRUE,col.line='red',cex.main=2,...){
oldpar<-par(no.readonly=TRUE)
y<-as.data.frame(subset(data,select=eval(parse(text=y)))) #select y variable
x<-as.data.frame(subset(data,select=eval(parse(text=x)))) #select y variable
#loop thru y variables
for(i in 1:ncol(y)){
#loop thru x variables
for (j in 1:ncol(x)){
#scatter plot
plot(x[,j],y[,i],yaxs='i',xaxs='i',
xlab=names(x[j]),ylab=names(y[i]),
main=paste(names(x[j]),'vs',names(y[i]),sep='  '),
cex.main=cex.main,...)
if(lowess==TRUE){
ok<-is.finite(x[,j]) & is.finite(y[,i])
if(any(ok))	lines(lowess(x[,j][ok],y[,i][ok]),col=col.line)
}
if(!j==ncol(x) | !i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru x variables
} #end loop thru y variables
par(oldpar)
} #end function
`sum.stats` <-
function(x,var='',by='',margin='column',...){
if(!var==''){
y<-subset(x,select=eval(parse(text=var))) #select variables to summarize
}
else{y<-x}
variable<-colnames(y)
sample<-rownames(y)
#statistical functions
nobs<<-function(x,na.rm) length(x)
cv<<-function(x,na.rm) sd(x,na.rm=TRUE)/mean(x,na.rm=TRUE)*100
xeros<<-function(x,na.rm) sum(x==0,na.rm=TRUE)
pct.xeros<<-function(x,na.rm) sum(x==0,na.rm=TRUE)/length(x)*100
nobs.missing<<-function(x,na.rm) sum(is.na(x))
pct.missing<<-function(x,na.rm) sum(is.na(x))/length(x)*100
se<<-function(x,na.rm) sd(x,na.rm=TRUE)/sqrt(length(x)-sum(is.na(x)))
se.ratio<<-function(x,na.rm) se(x)/mean(x,na.rm=TRUE)*100
richness<<-function(x,na.rm) nobs(x)-xeros(x)-nobs.missing(x)
sh.diversity<<-function(x,na.rm) -sum(((x)/sum(x,na.rm=TRUE))*log(((x)/sum(x,na.rm=TRUE))),na.rm=TRUE)
sh.evenness<<-function(x,na.rm) sh.diversity(x)/log(richness(x))
si.diversity<<-function(x,na.rm){
if(richness(x)==0) 0
else 1-sum(((x)/sum(x,na.rm=TRUE))*((x)/sum(x,na.rm=TRUE)),na.rm=TRUE)
}
si.evenness<<-function(x,na.rm) si.diversity(x)/(1-(1/richness(x)))
if(by==''){ #summary table w/o groups
if(margin=='column'){ #summary table by columns
z1<-data.frame(apply(y,2,function(x){ #calculate stats
z1<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sum(x,na.rm=TRUE),
sd(x,na.rm=TRUE),cv(x),xeros(x),pct.xeros(x),nobs.missing(x),
pct.missing(x),se(x),se.ratio(x),richness(x),sh.diversity(x),
sh.evenness(x),si.diversity(x),si.evenness(x))
names(z1)<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create col names
z1<-round(z1,3) #round elements to 3 decimal places
}))
z2<-data.frame(t(apply(z1,1,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
})))
z<-list(z1,z2) #create list with col stats and sum stats
names(z)<-c('Column.Summary','Table.Summary')
} #end summary table by columns
else{ #summary table by rows
z1<-data.frame(t(apply(y,1,function(x){ #calculate stats
z1<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sum(x,na.rm=TRUE),
sd(x,na.rm=TRUE),cv(x),xeros(x),pct.xeros(x),nobs.missing(x),
pct.missing(x),se(x),se.ratio(x),richness(x),sh.diversity(x),
sh.evenness(x),si.diversity(x),si.evenness(x))
names(z1)<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create col names
z1<-round(z1,3) #round elements to 3 decimal places
})))
z2<-data.frame(apply(z1,2,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
}))
z<-list(z1,z2) #create list with row stats and sum stats
names(z)<-c('Row.Summary','Table.Summary')
} #end summary table by rows
} #end summary table w/o groups
else{ #summary table w/ groups
#	write('',file=paste(outfile,'.csv',sep='')) #empty outfile if it exists
fns<-c('nobs','min','max','mean',
'median','sum','sd','cv','xeros','pct.xeros',
'nobs.missing','pct.missing','se','se.ratio',
'richness','sh.diversity','sh.evenness',
'si.diversity','si.evenness') #create names vector
n<-by.names(x,by) #create by variable
for(i in 1:length(fns)){ #loop thru by groups
cat(t<-paste(strtrim(paste('--',fns[i],paste(rep('-',80),collapse='')),80),'\n')) #create line break
q<-list(n[,2]) #create a list of group names
names(q)<-names(n)[2] #assign by name to q
z1<-aggregate(y,q,fns[i],na.rm=TRUE) #calculate stats
zz1<-round(z1[,2:ncol(z1)],3) #round stats to 3 decimal places
g<-z1[,1,,drop=FALSE] #select group variable
z1<-cbind(g,zz1) #bind group variable with selected variables
z2<-data.frame(t(apply(z1[,-1],1,function(x){ #calculate stats on stats
z2<-c(nobs(x),min(x,na.rm=TRUE),max(x,na.rm=TRUE),
mean(x,na.rm=TRUE),median(x,na.rm=TRUE),sd(x,na.rm=TRUE),cv(x))
names(z2)<-c('nobs','min','max','mean',
'median','sd','cv') #create row names
z2<-round(z2,3) #round elements to 3 decimal places
})))
z<-cbind(z1,z2) #bind col stats with summary stats
print(z) #print to console
} #end loop thru groups
} #end summary table w/ groups
return(z)
} #end function
`tau` <-
function(y,prior){
z<-matrix(0,nrow(y),ncol(y)) #create blank matrix
N<-sum(y)
ccr<-sum(diag(y))
n<-apply(y,1,sum)
num<-ccr-sum(prior*n)
den<-N-sum(prior*n)
tau<-num/den
tau[tau<0]<-0
return(tau)
}
`uv.outliers` <-
function(x,id,var,by=NULL,outfile=NULL,sd.limit=3,digits=3){
#sd outliers w/o groups
if(is.null(by)){
y1<-as.data.frame(subset(x,select=eval(parse(text=id)))) #select plot.id variables
y2<-as.data.frame(subset(x,select=eval(parse(text=var)))) #select variables to standardize
t1<-scale(y2) #calculate sd's
t2<-abs(t1)>=sd.limit
row.vector<-apply(t2,1,FUN='any',na.rm=TRUE)#select rows with extremes
col.vector<-apply(t2,2,FUN='any',na.rm=TRUE)#select cols with extremes
if(sum(row.vector)>0){
t3<-t1[row.vector,col.vector,drop=FALSE]
t3[abs(t3)<sd.limit]<-NA
t3<-round(t3,digits)
t4<-as.data.frame(y1[row.vector,,drop=FALSE])
z<-cbind(t4,t3)
if(!is.null(outfile)){ #write table to outfile
write.table(z,file=paste(outfile,'.csv',sep=''),row.names=FALSE,quote=FALSE,sep=',')
} #end save outfile
}
else stop('No outliers exist')
} #end sd outliers w/o groups
#sd outliers w/ groups
else{
if(!is.null(outfile)) write('',file=outfile) #empty outfile if it exists
n<-by.names(x,by) #create by variable
y<-cbind(n,x)
m<-levels(n[,2]) #create object with group levels
z<-vector('list',length(m))	#create list object for output
names(z)<-m #assign names to list components
for(i in 1:length(m)){ #loop thru by groups
t0<-y[n[,2]==m[i],,drop=FALSE] #select records within group
y1<-as.data.frame(subset(t0,select=eval(parse(text=id)))) #select plot.id variables
y2<-as.data.frame(subset(t0,select=eval(parse(text=var)))) #select variables to standardize
t1<-scale(y2) #calculate sd's
t2<-abs(t1)>=sd.limit
row.vector<-apply(t2,1,FUN='any',na.rm=TRUE)#select rows with extremes
col.vector<-apply(t2,2,FUN='any',na.rm=TRUE)#select cols with extremes
if(sum(row.vector)>0){
t3<-t1[row.vector,col.vector,drop=FALSE]
t3[abs(t3)<sd.limit]<-NA
t3<-round(t3,digits)
t4<-as.data.frame(y1[row.vector,,drop=FALSE])
z[[i]]<-cbind(t4,t3)
if(!is.null(outfile)){ #write table to outfile
write(m[i],file=paste(outfile,'.csv',sep=''),append=TRUE)
write.table(z,file=paste(outfile,'.csv',sep=''),quote=FALSE,append=TRUE,sep=',')
} #end save outfile
}
else z[[i]]<-NULL
} #end loop thru groups
} #end sd outliers w/groups
return(z)
} #end function
`uv.plots` <-
function(x,var=NULL,col.fill='blue',col.point='black',
col.line='red',...){
oldpar<-par(no.readonly=TRUE)
if(!is.null(var)){
y<-subset(x,select=eval(parse(text=var))) #select variables to summarize
y<-as.data.frame(y)
}
else{y<-as.data.frame(x)} #graphics settings
#layout plot
layout(matrix(c(1,1,2,3,4,5),
nrow=3,ncol=2,byrow=TRUE),
heights=c(.1,.45,.45),widths=c(.5,.5))
par(mar=c(1,1,1,1))
#loop thru variables
for(i in 1:ncol(y)){
#plot title
plot.new()
text(.5,.5,labels=names(y[i]),
font=2,cex=3,xpd=TRUE)
#histogram (upper left panel)
par(mar=c(5,5,4,2))
hist(y[[i]],prob=TRUE,col=col.fill,
xaxs='i',yaxs='i',xlab=names(y[i]),
main='Histogram',...)
lines(density(y[[i]]))
#box-and-whisker plot (upper right panel)
par(mar=c(5,5,4,2))
boxplot(y[i],col=col.fill,ylab=names(y[i]),
main='Box-and-Whisker Plot',...)
#empirical cumulative distribution function plot (lower left panel)
par(mar=c(5,5,4,2))
plot(sort(y[[i]]),type='o',col=col.point,yaxs='i',xaxs='i',
xlab='Cumulative Number of Plots',ylab=names(y[i]),
main='ECDF Plot',...)
#normal quantile-quantile plot (lower right panel)
par(mar=c(5,5,4,2))
qqnorm(y[,i],datax=TRUE,col=col.point,
main='Normal Q-Q Plot',...)
y.IQR<-IQR(y[,i],na.rm=TRUE)
if(y.IQR>0)	qqline(y[,i],datax=TRUE,col=col.line,...)
par(mar=c(1,1,1,1))
if(!i==ncol(y)) {readline("Press return for next plot ")}
} #end loop thru variables
par(oldpar)
} #end function
install.packages("vegan") #Install vegan package
library(vegan)
area.protID2 <- uniqueTransitionProteinAreas[-1]
rownames(area.protID2) <- uniqueTransitionProteinAreas[,1]
area2.t <- t(area.protID2[,1:10])
area2.tra <- (area2.t+1)
area2.tra <- data.trans(area2.tra, method = 'log', plot = FALSE)
area.protID2 <- uniqueTransitionProteinAreas[-1]
rownames(area.protID2) <- uniqueTransitionProteinAreas[,1]
head(uniqueTransitionProteinAreas) #Confirm merge
uniqueTransitionProteinAreas <- uniqueTransitionProteinAreas[,-2]
head(uniqueTransitionProteinAreas) #Confirm changes
uniqueTransitionProteinAreas[is.na(uniqueTransitionProteinAreas)] <- 0 #Replace NAs with 0s
head(uniqueTransitionProteinAreas) #Confirm changes
area.protID2 <- uniqueTransitionProteinAreas[-1]
rownames(area.protID2) <- uniqueTransitionProteinAreas[,1]
View(uniqueTransitionProteinAreas)
uniqueTransitionProteins <- unique(transitionProteins) #Removing duplicate entries from transitionProteins
View(uniqueTransitionProteins)
uniqueTransitionProteins <- unique(transitionProteins[,2]) #Removing duplicate entries from transitionProteins
head(uniqueTransitionProteins) #Confirm changes
uniqueTransitionProteinAreas <- merge(uniqueTransitionProteins, averageProteinAreasMerged, by = "protein")
uniqueTransitionProteins <- unique(transitionProteins) #Removing duplicate entries from transitionProteins
uniqueTransitionProteins <- unique(transitionProteins) #Removing duplicate entries from transitionProteins
uniqueTransitionProteins <- unique(uniqueTransitionProteins)
View(uniqueTransitionProteins)
uniqueTransitionProteinAreas <- unique(uniqueTransitionProteinAreas)
View(uniqueTransitionProteinAreas)
head(uniqueTransitionProteinAreas)
View(uniqueTransitionProteinAreas)
uniqueTransitionProteinAreas[is.na(uniqueTransitionProteinAreas)] <- 0 #Replace NAs with 0s
head(uniqueTransitionProteinAreas) #Confirm changes
area.protID2 <- uniqueTransitionProteinAreas[-1]
rownames(area.protID2) <- uniqueTransitionProteinAreas[,1]
area2.t <- t(area.protID2[,1:10])
area2.tra <- (area2.t+1)
area2.tra <- data.trans(area2.tra, method = 'log', plot = FALSE)
proc.nmds <- metaMDS(area2.tra, distance = 'bray', k = 2, trymax = 100, autotransform = FALSE)
fig.nmds <- ordiplot(proc.nmds, choices=c(1,2), type='none', display='sites', xlab='Axis 1', ylab='Axis 2', cex=0.5)
points(fig.nmds, 'sites', col=c('red', 'blue', 'black', 'green', 'magenta','red', 'blue', 'black', 'green', 'magenta'), pch=c(rep(16,5), rep(17,5)))
legend(-0.045,0.025, pch=c(rep(16,5), 1, 2), legend=c('Case Inlet', "Fidalgo Bay", "Willapa Bay", "Skokomish", "Port Gamble", "Bare", "Eelgrass"), col=c('red', 'blue', 'black', 'green', 'magenta', 'black', 'black'))
install.packages("pheatmap")
library(pheatmap)
pheatmap(area2.tra, cluster_rows = T, cluster_cols = T, clustering_distance_rows = 'euclidean', clustering_distance_cols = 'euclidean', clustering_method = 'average', show_rownames = T, show_colnames = F)
?jpeg
jpeg(filename = "fullHeatmap.jpeg")
pheatmap(area2.tra, cluster_rows = T, cluster_cols = T, clustering_distance_rows = 'euclidean', clustering_distance_cols = 'euclidean', clustering_method = 'average', show_rownames = T, show_colnames = F)
dev.off()
fig.nmds <- ordiplot(proc.nmds, choices=c(1,2), type='none', display='sites', xlab='Axis 1', ylab='Axis 2', cex=0.5)
points(fig.nmds, 'sites', col=c('red', 'blue', 'black', 'green', 'magenta','red', 'blue', 'black', 'green', 'magenta'), pch=c(rep(16,5), rep(17,5)))
legend(0,0.06, pch=c(rep(16,5), 1, 2), legend=c('Case Inlet', "Fidalgo Bay", "Willapa Bay", "Skokomish", "Port Gamble", "Bare", "Eelgrass"), col=c('red', 'blue', 'black', 'green', 'magenta', 'black', 'black'))
jpeg(filename = "transitionHeatmap.jpeg")
pheatmap(area2.tra, cluster_rows = T, cluster_cols = T, clustering_distance_rows = 'euclidean', clustering_distance_cols = 'euclidean', clustering_method = 'average', show_rownames = T, show_colnames = F)
dev.off()
proteinAnnotationsEvalues <- read.csv(file = "/Users/yaaminivenkataraman/Documents/project-oyster-oa/analyses/DNR_TransitionSelection_20170707/2017-07-07-Preliminary-Transitions/2017-07-07-Gigas-Annotations-Evalues.csv", header = FALSE, col.names = c("C1", "averageProteinAreas.protein", "C3", "C4", "C5", "C6", "C7", "C8", "C9", "C10", "C11", "C12", "Evalue", "C14", "C15", "reviewed", "Annotation", "C18", "Species", "C20", "BiologicalProcess", "GOTerm", "Pathway", "C24", "C25", "C26")) #Import full annotation
head(proteinAnnotationsEvalues)
proteinAnnotationsEvalues <- read.csv(file = "/Users/yaaminivenkataraman/Documents/project-oyster-oa/analyses/DNR_TransitionSelection_20170707/2017-07-07-Preliminary-Transitions/2017-07-07-Gigas-Annotations-Evalues.csv", header = FALSE, col.names = c("C1", "protein", "C3", "C4", "C5", "C6", "C7", "C8", "C9", "C10", "C11", "C12", "Evalue", "C14", "C15", "reviewed", "Annotation", "C18", "Species", "C20", "BiologicalProcess", "GOTerm", "Pathway", "C24", "C25", "C26")) #Import full annotation
head(proteinAnnotationsEvalues)
goTerms <- proteinAnnotationsEvalues[,c(2,22)]
head(goTerms) #Confirm isolation
uniqueTransitionProteinAreasGO <- merge(x = uniqueTransitionProteinAreas, y = goTerms, by = "protein") #Merge unique transition proteins and area with GOterms
head(uniqueTransitionProteinAreasGO) #Confirm merge
sitesAndEelgrass <- read.csv(file = "/Users/yaaminivenkataraman/Documents/project-oyster-oa/analyses/DNR_TransitionSelection_20170707/2017-07-07-Preliminary-Transitions/2017-07-05-SitesEelgrass-Accession-nohead.csv")
View(sitesAndEelgrass)
head(sitesAndEelgrass)
goTermspValues <- sitesAndEelgrass[,c(1, 8, 18)]
head(goTermspValues)
names(goTermspValues) <- c("protein", "adj.pvalue", "goterm")
head(goTermspValues)
merge(x = uniqueTransitionProteinAreas, y = goTermspValues, by = "protein")
uniqueTransitionProteinAreasGO <- merge(x = uniqueTransitionProteinAreas, y = goTermspValues, by = "protein")
head(uniqueTransitionProteinAreasGO)
View(uniqueTransitionProteinAreas)
View(uniqueTransitionProteinAreasGO)
write.csv(x = uniqueTransitionProteinAreasGO, file = "2017-07-18-Transition-Proteins-GOTerms-PValues.csv", header = TRUE)
write.csv(x = uniqueTransitionProteinAreasGO, file = "2017-07-18-Transition-Proteins-for-REVIGO.csv", header = TRUE)
write.csv(x = uniqueTransitionProteinAreasGO, file = "2017-07-18-Transition-Proteins-for-REVIGO.csv")
?ordiplot
??ordiplot
